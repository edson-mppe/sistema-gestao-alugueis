{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e792060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gspread\n",
    "import os\n",
    "from IPython.display import display\n",
    "import locale\n",
    "from datetime import datetime, date, time\n",
    "# (Presume que google-auth, etc., estão instalados)\n",
    "\n",
    "# (Presume que a autenticação (credentials2.json) está configurada \n",
    "#  para uma conta de serviço)\n",
    "\n",
    "# Tenta configurar o locale para Português do Brasil para formatar datas\n",
    "try:\n",
    "    locale.setlocale(locale.LC_TIME, 'pt_BR.UTF-8')\n",
    "except locale.Error:\n",
    "    try:\n",
    "        locale.setlocale(locale.LC_TIME, 'Portuguese_Brazil.1252')\n",
    "    except locale.Error:\n",
    "        print(\"Aviso: Não foi possível definir o locale para 'pt_BR'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d78ef77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import locale\n",
    "from datetime import datetime, date, time\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Mapa de Meses (Constante) ---\n",
    "# Usamos strings '01', '02', etc., para a substituição (replace)\n",
    "MESES_MAP_REPLACE = {\n",
    "    'jan': '01', 'fev': '02', 'mar': '03', 'abr': '04', \n",
    "    'mai': '05', 'jun': '06', 'jul': '07', 'ago': '08', \n",
    "    'set': '09', 'out': '10', 'nov': '11', 'dez': '12'\n",
    "}\n",
    "\n",
    "def tratar_dataframe_consolidado(df_consolidado):\n",
    "    \"\"\"\n",
    "    Limpa, formata, atualiza o status e filtra o DataFrame consolidado.\n",
    "    \n",
    "    1. Remove linhas onde a coluna 'Início' está vazia.\n",
    "    2. (NOVO) Remove linhas onde 'Status' contém apenas números.\n",
    "    3. Converte 'Início' e 'Fim' (do formato 'DD-Mês.YY-Dia') \n",
    "       usando a lógica rsplit -> replace.\n",
    "    4. Adiciona 15h ao 'Início' e 11h ao 'Fim'.\n",
    "    5. (NOVO) Renomeia 'CANCELADO COM CRÉDITO' para 'Cancelado'.\n",
    "    6. (NOVO) Define o Status como 'Concluído' se a data 'Fim' já passou.\n",
    "    7. Reformata para a string 'DD/MM/AAAA HH:MM'.\n",
    "    8. Filtra o DataFrame final para manter apenas as 19 colunas especificadas.\n",
    "\n",
    "    Args:\n",
    "        df_consolidado (pd.DataFrame): O DataFrame lido da planilha \n",
    "                                     (ex: '20-jun.25-sex.').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: O DataFrame tratado e filtrado.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Iniciando tratamento do DataFrame (Tamanho original: {len(df_consolidado)} linhas)...\")\n",
    "    \n",
    "    # 1. Faz uma cópia para evitar modificar o original\n",
    "    df_tratado = df_consolidado.copy()\n",
    "    \n",
    "    # --- 2. Remover linhas com 'Início' vazio ---\n",
    "    linhas_antes = len(df_tratado)\n",
    "    df_tratado = df_tratado[pd.notna(df_tratado['Início'])]\n",
    "    df_tratado = df_tratado[df_tratado['Início'].astype(str).str.strip() != '']\n",
    "    linhas_depois = len(df_tratado)\n",
    "    print(f\"  Removidas {linhas_antes - linhas_depois} linhas com 'Início' vazio.\")\n",
    "\n",
    "    # --- (NOVA ETAPA 1) Remover Status numérico ---\n",
    "    if 'Status' in df_tratado.columns:\n",
    "        linhas_antes = len(df_tratado)\n",
    "        # pd.to_numeric(..., errors='coerce') cria NaN para não-números (ex: 'Cancelado')\n",
    "        # .isna() marca True para não-números (que queremos manter)\n",
    "        linhas_para_manter = pd.to_numeric(df_tratado['Status'], errors='coerce').isna()\n",
    "        df_tratado = df_tratado[linhas_para_manter]\n",
    "        print(f\"  Removidas {linhas_antes - len(df_tratado)} linhas com 'Status' puramente numérico.\")\n",
    "    else:\n",
    "        print(\"  Aviso: Coluna 'Status' não encontrada para filtro numérico.\")\n",
    "\n",
    "    # --- 3. Parsear e Formatar 'Início' e 'Fim' (Cria _dt) ---\n",
    "    print(\"  Parseando e formatando datas (Início e Fim)...\")\n",
    "    colunas_para_processar = {'Início': '15 hours', 'Fim': '11 hours'}\n",
    "    colunas_dt_temporarias = [] \n",
    "\n",
    "    for col_nome, timedelta_str in colunas_para_processar.items():\n",
    "        if col_nome not in df_tratado.columns:\n",
    "            print(f\"  Aviso: Coluna '{col_nome}' não encontrada. Pulando.\")\n",
    "            continue\n",
    "        col_dt_temp = f\"{col_nome}_dt\"\n",
    "        colunas_dt_temporarias.append(col_dt_temp)\n",
    "        # Etapas A, B, C, D (Lógica de parse e adição de horas)\n",
    "        datas_limpas = df_tratado[col_nome].astype(str).str.rsplit('-', n=1).str[0].str.strip()\n",
    "        temp_series = datas_limpas.str.lower()\n",
    "        for pt_mes, num_mes in MESES_MAP_REPLACE.items():\n",
    "            temp_series = temp_series.str.replace(pt_mes, num_mes)\n",
    "        df_tratado[col_dt_temp] = pd.to_datetime(temp_series, format='%d-%m.%y', errors='coerce')\n",
    "        timedelta = pd.to_timedelta(timedelta_str)\n",
    "        valid_dates = df_tratado[col_dt_temp].notna()\n",
    "        df_tratado.loc[valid_dates, col_dt_temp] = df_tratado.loc[valid_dates, col_dt_temp] + timedelta\n",
    "\n",
    "    # --- 4. Remover linhas onde o parse de data falhou (virou NaT) ---\n",
    "    if colunas_dt_temporarias:\n",
    "        linhas_antes_parse = len(df_tratado)\n",
    "        df_tratado.dropna(subset=colunas_dt_temporarias, inplace=True)\n",
    "        erros_parse = linhas_antes_parse - len(df_tratado)\n",
    "        if erros_parse > 0:\n",
    "            print(f\"  Removidas {erros_parse} linhas onde 'Início' ou 'Fim' tinham formato de data inválido.\")\n",
    "            \n",
    "    # --- 5. (NOVAS ETAPAS 2 & 3) Atualização de Status ---\n",
    "    if 'Status' in df_tratado.columns:\n",
    "        \n",
    "        # (ETAPA 2) Renomear 'CANCELADO COM CRÉDITO' para 'Cancelado'\n",
    "        print(\"  Renomeando Status 'CANCELADO COM CRÉDITO'...\")\n",
    "        df_tratado['Status'] = df_tratado['Status'].replace(\n",
    "            'CANCELADO COM CRÉDITO', 'Cancelado'\n",
    "        )\n",
    "        \n",
    "        # (ETAPA 3) Colocar 'Concluído' se 'Fim_dt' já passou\n",
    "        if 'Fim_dt' in df_tratado.columns:\n",
    "            print(\"  Atualizando Status para 'Concluído' em reservas passadas...\")\n",
    "            # Pega a data/hora exata de agora\n",
    "            agora = pd.to_datetime('now')\n",
    "            # Define a condição (Onde Fim_dt é anterior a agora)\n",
    "            condicao_concluido = df_tratado['Fim_dt'] < agora\n",
    "            # Atualiza 'Status' usando .loc\n",
    "            df_tratado.loc[condicao_concluido, 'Status'] = 'Concluído'\n",
    "            print(f\"    {condicao_concluido.sum()} linhas atualizadas para 'Concluído'.\")\n",
    "        else:\n",
    "            print(\"  Aviso: Coluna 'Fim_dt' não encontrada, não foi possível atualizar para 'Concluído'.\")\n",
    "            \n",
    "    else:\n",
    "        print(\"  Aviso: Coluna 'Status' não encontrada para aplicar regras de negócio.\")\n",
    "\n",
    "    # --- 6. Reformatar colunas originais para 'DD/MM/AAAA HH:MM' ---\n",
    "    print(\"  Reformatando colunas de data para 'DD/MM/YYYY HH:MM'...\")\n",
    "    if 'Início_dt' in df_tratado.columns:\n",
    "        df_tratado['Início'] = df_tratado['Início_dt'].dt.strftime('%d/%m/%Y %H:%M')\n",
    "    if 'Fim_dt' in df_tratado.columns:\n",
    "        df_tratado['Fim'] = df_tratado['Fim_dt'].dt.strftime('%d/%m/%Y %H:%M')\n",
    "    \n",
    "    # --- 7. Limpar colunas temporárias ---\n",
    "    df_tratado = df_tratado.drop(columns=colunas_dt_temporarias, errors='ignore')\n",
    "\n",
    "    # --- 8. Selecionar e Reordenar Colunas Finais ---\n",
    "    print(\"  Filtrando para colunas finais desejadas...\")\n",
    "    colunas_desejadas = [\n",
    "        'idReserva', 'Apartamento', 'Início', 'Fim', 'Dias', 'Pessoas',\n",
    "        'Quem', 'Origem', 'Recebido', 'Despesas', 'A receber', 'Total Lq',\n",
    "        'Total BT', 'Diária BT', 'Diária Lq', 'Com.', 'Diária BT PAX',\n",
    "        'Diária Lq PAX', 'Status','Data Reserva'\n",
    "    ]\n",
    "\n",
    "    colunas_finais_presentes = [col for col in colunas_desejadas if col in df_tratado.columns]\n",
    "    colunas_perdidas = [col for col in colunas_desejadas if col not in df_tratado.columns]\n",
    "    if colunas_perdidas:\n",
    "        print(f\"  Aviso: As seguintes colunas não foram encontradas e não estarão no resultado: {colunas_perdidas}\")\n",
    "\n",
    "    df_final_filtrado = df_tratado[colunas_finais_presentes]\n",
    "    \n",
    "    print(f\"Tratamento concluído. (Tamanho final: {len(df_final_filtrado)} linhas)\")\n",
    "    \n",
    "    return df_final_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6fdc80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_abas_planilha(sheet_key, lista_abas, credentials_path):\n",
    "    \"\"\"\n",
    "    Autentica no Google Sheets, abre uma planilha específica e lê\n",
    "    múltiplas abas (planilhas/worksheets) para DataFrames Pandas.\n",
    "    \n",
    "    Assume que os cabeçalhos estão na Linha 3 (índice 2) e os \n",
    "    dados começam na Linha 4 (índice 3) para TODAS as abas.\n",
    "\n",
    "    Args:\n",
    "        sheet_key (str): A chave (ID) da Planilha Google.\n",
    "        lista_abas (list): Uma lista de strings com os nomes das abas\n",
    "                           que devem ser lidas (ex: ['SM-C108', 'SM-D014']).\n",
    "        credentials_path (str): Caminho para o arquivo JSON da conta de serviço.\n",
    "\n",
    "    Returns:\n",
    "        dict: Um dicionário onde as chaves são os nomes das abas e \n",
    "              os valores são os DataFrames Pandas correspondentes.\n",
    "              Retorna None para abas que falharam na leitura.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n--- Iniciando leitura da Planilha Google (Key: {sheet_key}) ---\")\n",
    "    \n",
    "    # Dicionário para armazenar os DataFrames resultantes\n",
    "    dataframes_lidos = {}\n",
    "\n",
    "    # Verifica se o arquivo de credenciais existe\n",
    "    if not os.path.exists(credentials_path):\n",
    "        print(f\"ERRO: Arquivo de credenciais '{credentials_path}' não encontrado.\")\n",
    "        return None # Retorna None se a autenticação falhar\n",
    "\n",
    "    try:\n",
    "        # 1. Autenticar e Abrir a Planilha (uma única vez)\n",
    "        print(\"Autenticando com conta de serviço...\")\n",
    "        gc = gspread.service_account(filename=credentials_path)\n",
    "        print(\"Autenticação OK.\")\n",
    "\n",
    "        print(f\"Abrindo planilha...\")\n",
    "        sh = gc.open_by_key(sheet_key)\n",
    "        print(\"Planilha aberta com sucesso.\")\n",
    "\n",
    "    except gspread.exceptions.APIError as e_api:\n",
    "        print(f\"ERRO de API do Google: {e_api}\")\n",
    "        print(\"Verifique permissões, quotas e se a API está habilitada.\")\n",
    "        return None\n",
    "    except gspread.exceptions.SpreadsheetNotFound:\n",
    "         print(f\"ERRO: Planilha com key '{sheet_key}' não encontrada ou sem permissão.\")\n",
    "         return None\n",
    "    except Exception as e_auth:\n",
    "        print(f\"ERRO inesperado durante a autenticação ou abertura: {e_auth}\")\n",
    "        return None\n",
    "\n",
    "    # 2. Iterar sobre a lista de abas fornecida\n",
    "    for nome_aba in lista_abas:\n",
    "        print(f\"\\n  --- Processando aba: '{nome_aba}' ---\")\n",
    "        try:\n",
    "            # Seleciona a Aba\n",
    "            worksheet = sh.worksheet(nome_aba)\n",
    "            \n",
    "            # Lê Todos os Valores\n",
    "            # value_render_option='FORMATTED_VALUE' lê como exibido na planilha\n",
    "            all_values = worksheet.get_all_values(value_render_option='FORMATTED_VALUE')\n",
    "            \n",
    "            # Processa com Pandas (Cabeçalho na Linha 3, Dados da Linha 4)\n",
    "            if len(all_values) < 4:\n",
    "                print(f\"    Aviso: Aba '{nome_aba}' tem menos de 4 linhas. \"\n",
    "                      \"Retornando DataFrame vazio.\")\n",
    "                # Tenta pegar o cabeçalho se existir\n",
    "                headers = all_values[2] if len(all_values) >= 3 else []\n",
    "                dataframes_lidos[nome_aba] = pd.DataFrame(columns=headers)\n",
    "                continue # Pula para a próxima aba\n",
    "\n",
    "            headers = all_values[2] # Linha 3 (índice 2)\n",
    "            data = all_values[3:]   # Linha 4 (índice 3) em diante\n",
    "\n",
    "            # Cria o DataFrame\n",
    "            df = pd.DataFrame(data, columns=headers)\n",
    "            print(f\"    Aba '{nome_aba}' lida com sucesso. {len(df)} linhas de dados encontradas.\")\n",
    "            dataframes_lidos[nome_aba] = df\n",
    "\n",
    "        except gspread.exceptions.WorksheetNotFound:\n",
    "            print(f\"    ERRO: Aba '{nome_aba}' não foi encontrada na planilha. Pulando.\")\n",
    "            dataframes_lidos[nome_aba] = None # Indica falha para esta aba\n",
    "        except Exception as e:\n",
    "            print(f\"    ERRO inesperado ao processar a aba '{nome_aba}': {e}\")\n",
    "            dataframes_lidos[nome_aba] = None # Indica falha para esta aba\n",
    "\n",
    "    print(\"\\n--- Leitura de todas as abas concluída. ---\")\n",
    "    return dataframes_lidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b284abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unir_dataframes_lidos(dfs_lidos):\n",
    "    \"\"\"\n",
    "    Recebe um dicionário de DataFrames (lidos das abas), concatena todos,\n",
    "    substitui a coluna 'Apartamento' pelo nome da aba (chave do dicionário),\n",
    "    e cria uma nova coluna 'idReserva' sequencial.\n",
    "    \n",
    "    Esta versão inclui uma correção para colunas duplicadas nas abas de origem,\n",
    "    que é a causa provável do InvalidIndexError.\n",
    "\n",
    "    Args:\n",
    "        dfs_lidos (dict): Dicionário no formato {nome_aba: pd.DataFrame}.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Um único DataFrame consolidado e transformado,\n",
    "                      ou um DataFrame vazio se houver erro.\n",
    "    \"\"\"\n",
    "    \n",
    "    lista_dfs_processados = []\n",
    "\n",
    "    if not dfs_lidos:\n",
    "        print(\"Dicionário de DataFrames está vazio.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(\"Iniciando união e transformação dos DataFrames...\")\n",
    "\n",
    "    # Itera sobre o dicionário (nome_aba = chave, df_aba = valor)\n",
    "    for nome_aba, df_aba in dfs_lidos.items():\n",
    "        \n",
    "        # Pula abas que falharam na leitura (None) ou estão vazias\n",
    "        if df_aba is None or df_aba.empty:\n",
    "            print(f\"  Aviso: Aba '{nome_aba}' está vazia ou teve erro na leitura. Pulando.\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            df_processado = df_aba.copy()\n",
    "            \n",
    "            # --- CORREÇÃO OBRIGATÓRIA PARA O ERRO InvalidIndexError ---\n",
    "            # Verifica se os nomes das colunas nesta aba são únicos\n",
    "            if not df_processado.columns.is_unique:\n",
    "                print(f\"  Aviso: Corrigindo nomes de colunas duplicados na aba '{nome_aba}'.\")\n",
    "                cols = pd.Series(df_processado.columns)\n",
    "                for dup in cols[cols.duplicated()].unique():\n",
    "                    # Pega todas as posições da coluna duplicada\n",
    "                    dup_indices = cols[cols == dup].index.tolist()\n",
    "                    # Renomeia a partir da *segunda* ocorrência\n",
    "                    for i, idx in enumerate(dup_indices[1:], start=1):\n",
    "                        cols[idx] = f\"{dup}.{i}\"\n",
    "                df_processado.columns = cols\n",
    "            # --- FIM DA CORREÇÃO ---\n",
    "\n",
    "            # 2. Substitui a coluna 'Apartamento' pelo nome da aba\n",
    "            df_processado['Apartamento'] = nome_aba\n",
    "            \n",
    "            # 3. Descarta a coluna 'Id' original, se existir\n",
    "            if 'Id' in df_processado.columns:\n",
    "                df_processado = df_processado.drop(columns=['Id'])\n",
    "                \n",
    "            lista_dfs_processados.append(df_processado)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ERRO ao processar a aba '{nome_aba}': {e}. Pulando.\")\n",
    "\n",
    "    # Verifica se algum DataFrame foi processado\n",
    "    if not lista_dfs_processados:\n",
    "        print(\"Nenhum DataFrame válido foi processado.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 4. Concatena (empilha) todos os DataFrames processados em um só\n",
    "    # Esta linha agora deve funcionar graças à correção de colunas duplicadas\n",
    "    df_consolidado = pd.concat(lista_dfs_processados, ignore_index=True, sort=False)\n",
    "    \n",
    "    # 5. Adiciona o novo ID sequencial (chave primária)\n",
    "    df_consolidado['idReserva'] = df_consolidado.index + 1 # Começa em 1\n",
    "    \n",
    "    # 6. Reordena as colunas (opcional, mas bom para visualização)\n",
    "    colunas_principais = ['idReserva', 'Apartamento']\n",
    "    colunas_restantes = [col for col in df_consolidado.columns if col not in colunas_principais]\n",
    "    df_consolidado = df_consolidado[colunas_principais + colunas_restantes]\n",
    "    \n",
    "    print(f\"União concluída. DataFrame final com {len(df_consolidado)} linhas.\")\n",
    "    \n",
    "    return df_consolidado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "411e1b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "import pandas as pd\n",
    "import os\n",
    "# (Certifique-se de que as bibliotecas google-auth, etc., estão instaladas)\n",
    "\n",
    "def salvar_df_no_gsheet(df, sheet_key, worksheet_name, credentials_path, clear_sheet=True):\n",
    "    \"\"\"\n",
    "    Salva um DataFrame do Pandas em uma aba específica de uma Planilha Google.\n",
    "    Cria a aba, ajusta colunas, aplica um filtro para 'Status' em branco\n",
    "    E ORDENA pela coluna 'Início'.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Iniciando Upload para Google Sheet ---\")\n",
    "    print(f\"  Planilha Key: {sheet_key}\")\n",
    "    print(f\"  Aba         : {worksheet_name}\")\n",
    "\n",
    "    if not os.path.exists(credentials_path):\n",
    "        print(f\"ERRO: Arquivo de credenciais '{credentials_path}' não encontrado.\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        # 1. Autenticar\n",
    "        print(\"Autenticando com conta de serviço...\")\n",
    "        gc = gspread.service_account(filename=credentials_path)\n",
    "        print(\"Autenticação OK.\")\n",
    "\n",
    "        # 2. Abrir a Planilha\n",
    "        print(f\"Abrindo planilha...\")\n",
    "        sh = gc.open_by_key(sheet_key)\n",
    "        print(\"Planilha aberta.\")\n",
    "\n",
    "        # 3. Selecionar ou Criar a Aba\n",
    "        try:\n",
    "            worksheet = sh.worksheet(worksheet_name)\n",
    "            print(f\"Aba '{worksheet_name}' encontrada.\")\n",
    "        except gspread.exceptions.WorksheetNotFound:\n",
    "            print(f\"Aba '{worksheet_name}' não encontrada. Criando nova aba...\")\n",
    "            worksheet = sh.add_worksheet(title=worksheet_name, \n",
    "                                         rows=str(len(df) + 10), \n",
    "                                         cols=str(len(df.columns) + 2))\n",
    "            print(f\"Aba '{worksheet_name}' criada.\")\n",
    "\n",
    "        # 4. Limpar a Aba (se solicitado)\n",
    "        if clear_sheet:\n",
    "            print(f\"Limpando conteúdo existente da aba '{worksheet_name}'...\")\n",
    "            worksheet.clear()\n",
    "            print(\"Aba limpa.\")\n",
    "\n",
    "        # 5. Preparar os Dados (Cabeçalho + Linhas)\n",
    "        print(\"Preparando dados para upload...\")\n",
    "        df_upload = df.fillna('').astype(str)\n",
    "        dados_preparados = [df_upload.columns.values.tolist()] + df_upload.values.tolist()\n",
    "        num_rows, num_cols = df_upload.shape\n",
    "        print(f\"Dados preparados: {num_rows + 1} linhas, {num_cols} colunas.\")\n",
    "\n",
    "        # 6. Atualizar a Aba\n",
    "        print(f\"Enviando dados para a aba '{worksheet_name}' (iniciando em A1)...\")\n",
    "        \n",
    "        # --- CORREÇÃO APLICADA AQUI (usando argumentos nomeados) ---\n",
    "        worksheet.update(\n",
    "            range_name='A1', \n",
    "            values=dados_preparados, \n",
    "            value_input_option='USER_ENTERED'\n",
    "        )\n",
    "        # -----------------------------------------------------------\n",
    "        \n",
    "        print(\"Dados enviados com sucesso!\")\n",
    "\n",
    "        # 7. Ajustar o Tamanho das Colunas\n",
    "        print(\"Ajustando o tamanho das colunas...\")\n",
    "        try:\n",
    "            sheet_id = worksheet.id\n",
    "            body_resize = {\n",
    "                \"requests\": [\n",
    "                    {\n",
    "                        \"autoResizeDimensions\": {\n",
    "                            \"dimensions\": {\n",
    "                                \"sheetId\": sheet_id,\n",
    "                                \"dimension\": \"COLUMNS\",\n",
    "                                \"startIndex\": 0,\n",
    "                                \"endIndex\": num_cols\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            sh.batch_update(body_resize)\n",
    "            print(\"Tamanho das colunas ajustado com sucesso.\")\n",
    "        except Exception as e_resize:\n",
    "            print(f\"  AVISO: Falha ao tentar ajustar o tamanho das colunas: {e_resize}\")\n",
    "            \n",
    "        # (ETAPA ATUALIZADA) ADICIONAR FILTRO PRÉ-DEFINIDO E ORDENAÇÃO\n",
    "        print(\"Adicionando filtro (Status=Em Branco) e ordenando por 'Início'...\")\n",
    "        try:\n",
    "            # Precisamos encontrar os índices (base 0) das colunas\n",
    "            try:\n",
    "                status_col_index = df_upload.columns.get_loc('Status') \n",
    "                inicio_col_index = df_upload.columns.get_loc('Início')\n",
    "            except KeyError as e:\n",
    "                print(f\"  ERRO: Coluna 'Status' ou 'Início' não encontrada no DataFrame. Não é possível aplicar filtro/ordenação. Erro: {e}\")\n",
    "                return True \n",
    "\n",
    "            sheet_id = worksheet.id\n",
    "            \n",
    "            body_filter_sort = {\n",
    "                \"requests\": [\n",
    "                    {\n",
    "                        \"setBasicFilter\": {\n",
    "                            \"filter\": {\n",
    "                                \"range\": {\n",
    "                                    \"sheetId\": sheet_id,\n",
    "                                    \"startRowIndex\": 0, # Linha 1 (cabeçalho)\n",
    "                                    \"endRowIndex\": num_rows + 1,\n",
    "                                    \"startColumnIndex\": 0,\n",
    "                                    \"endColumnIndex\": num_cols\n",
    "                                },\n",
    "                                \"sortSpecs\": [\n",
    "                                    {\n",
    "                                        \"dimensionIndex\": inicio_col_index, # Índice da coluna 'Início'\n",
    "                                        \"sortOrder\": \"ASCENDING\"\n",
    "                                    }\n",
    "                                ],\n",
    "                                \"criteria\": {\n",
    "                                    str(status_col_index): {\n",
    "                                        \"condition\": {\n",
    "                                            \"type\": \"BLANK\"\n",
    "                                        }\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            sh.batch_update(body_filter_sort)\n",
    "            print(\"Autofiltro (Status=Branco) e ordenação por 'Início' aplicados com sucesso.\")\n",
    "\n",
    "        except Exception as e_filter:\n",
    "            print(f\"  AVISO: Falha ao tentar adicionar o autofiltro/ordenação: {e_filter}\")\n",
    "            \n",
    "        return True \n",
    "\n",
    "    except gspread.exceptions.APIError as e_api:\n",
    "        print(f\"ERRO de API do Google: {e_api}\")\n",
    "        print(\"Verifique permissões, quotas e se a API está habilitada.\")\n",
    "        return False\n",
    "    except gspread.exceptions.SpreadsheetNotFound:\n",
    "         print(f\"ERRO: Planilha com key '{sheet_key}' não encontrada ou sem permissão.\")\n",
    "         return False\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO inesperado durante operação com Google Sheets: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e8527a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando leitura da Planilha Google (Key: 1FqgTQAGebxvHUdVXI471HpAaXeXyCFdFWur7Pck0hLY) ---\n",
      "Autenticando com conta de serviço...\n",
      "Autenticação OK.\n",
      "Abrindo planilha...\n",
      "Planilha aberta com sucesso.\n",
      "\n",
      "  --- Processando aba: 'SM-C108' ---\n",
      "    Aba 'SM-C108' lida com sucesso. 88 linhas de dados encontradas.\n",
      "\n",
      "  --- Processando aba: 'SM-D014' ---\n",
      "    Aba 'SM-D014' lida com sucesso. 15 linhas de dados encontradas.\n",
      "\n",
      "  --- Processando aba: 'CBL004' ---\n",
      "    Aba 'CBL004' lida com sucesso. 375 linhas de dados encontradas.\n",
      "\n",
      "  --- Processando aba: 'AP-101' ---\n",
      "    Aba 'AP-101' lida com sucesso. 580 linhas de dados encontradas.\n",
      "\n",
      "  --- Processando aba: 'AP-201' ---\n",
      "    Aba 'AP-201' lida com sucesso. 578 linhas de dados encontradas.\n",
      "\n",
      "--- Leitura de todas as abas concluída. ---\n",
      "Iniciando união e transformação dos DataFrames...\n",
      "União concluída. DataFrame final com 1636 linhas.\n",
      "Iniciando tratamento do DataFrame (Tamanho original: 1636 linhas)...\n",
      "  Removidas 59 linhas com 'Início' vazio.\n",
      "  Removidas 2 linhas com 'Status' puramente numérico.\n",
      "  Parseando e formatando datas (Início e Fim)...\n",
      "  Renomeando Status 'CANCELADO COM CRÉDITO'...\n",
      "  Atualizando Status para 'Concluído' em reservas passadas...\n",
      "    1496 linhas atualizadas para 'Concluído'.\n",
      "  Reformatando colunas de data para 'DD/MM/YYYY HH:MM'...\n",
      "  Filtrando para colunas finais desejadas...\n",
      "Tratamento concluído. (Tamanho final: 1575 linhas)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idReserva</th>\n",
       "      <th>Apartamento</th>\n",
       "      <th>Início</th>\n",
       "      <th>Fim</th>\n",
       "      <th>Dias</th>\n",
       "      <th>Pessoas</th>\n",
       "      <th>Quem</th>\n",
       "      <th>Origem</th>\n",
       "      <th>Recebido</th>\n",
       "      <th>Despesas</th>\n",
       "      <th>A receber</th>\n",
       "      <th>Total Lq</th>\n",
       "      <th>Total BT</th>\n",
       "      <th>Diária BT</th>\n",
       "      <th>Diária Lq</th>\n",
       "      <th>Com.</th>\n",
       "      <th>Diária BT PAX</th>\n",
       "      <th>Diária Lq PAX</th>\n",
       "      <th>Status</th>\n",
       "      <th>Data Reserva</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SM-C108</td>\n",
       "      <td>20/06/2025 15:00</td>\n",
       "      <td>24/06/2025 11:00</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mariana</td>\n",
       "      <td>Direto</td>\n",
       "      <td>1.800,00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.800,00</td>\n",
       "      <td>1.800,00</td>\n",
       "      <td>450,00</td>\n",
       "      <td>450,00</td>\n",
       "      <td>0%</td>\n",
       "      <td>90,00</td>\n",
       "      <td>90,00</td>\n",
       "      <td>Concluído</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SM-C108</td>\n",
       "      <td>08/07/2025 15:00</td>\n",
       "      <td>13/07/2025 11:00</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Alex Palmer +55 63 99991 9458</td>\n",
       "      <td>Booking</td>\n",
       "      <td>1.084,02</td>\n",
       "      <td></td>\n",
       "      <td>0,00</td>\n",
       "      <td>1.084,02</td>\n",
       "      <td>1.246,00</td>\n",
       "      <td>249,20</td>\n",
       "      <td>216,80</td>\n",
       "      <td>13%</td>\n",
       "      <td>49,84</td>\n",
       "      <td>43,36</td>\n",
       "      <td>Concluído</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SM-C108</td>\n",
       "      <td>13/07/2025 15:00</td>\n",
       "      <td>15/07/2025 11:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>‪Weiman Pereira +55 66 98448-1056‬</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>400,96</td>\n",
       "      <td>400,96</td>\n",
       "      <td>490,26</td>\n",
       "      <td>245,13</td>\n",
       "      <td>200,48</td>\n",
       "      <td>18%</td>\n",
       "      <td>122,56</td>\n",
       "      <td>100,24</td>\n",
       "      <td>Concluído</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SM-C108</td>\n",
       "      <td>16/07/2025 15:00</td>\n",
       "      <td>18/07/2025 11:00</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Paula Andrade +55 81 99716 3944</td>\n",
       "      <td>Booking</td>\n",
       "      <td>436,74</td>\n",
       "      <td></td>\n",
       "      <td>0,00</td>\n",
       "      <td>436,74</td>\n",
       "      <td>502,00</td>\n",
       "      <td>251,00</td>\n",
       "      <td>218,37</td>\n",
       "      <td>13%</td>\n",
       "      <td>50,20</td>\n",
       "      <td>43,67</td>\n",
       "      <td>Concluído</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SM-C108</td>\n",
       "      <td>18/07/2025 15:00</td>\n",
       "      <td>20/07/2025 11:00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Cláudia +55 81 99974-5581‬</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>290,00</td>\n",
       "      <td></td>\n",
       "      <td>292,39</td>\n",
       "      <td>582,39</td>\n",
       "      <td>712,09</td>\n",
       "      <td>356,05</td>\n",
       "      <td>291,20</td>\n",
       "      <td>18%</td>\n",
       "      <td>89,01</td>\n",
       "      <td>72,80</td>\n",
       "      <td>Concluído</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idReserva Apartamento            Início               Fim Dias Pessoas  \\\n",
       "0          1     SM-C108  20/06/2025 15:00  24/06/2025 11:00    4       5   \n",
       "1          2     SM-C108  08/07/2025 15:00  13/07/2025 11:00    5       5   \n",
       "2          3     SM-C108  13/07/2025 15:00  15/07/2025 11:00    2       2   \n",
       "3          4     SM-C108  16/07/2025 15:00  18/07/2025 11:00    2       5   \n",
       "4          5     SM-C108  18/07/2025 15:00  20/07/2025 11:00    2       4   \n",
       "\n",
       "                                  Quem   Origem  Recebido Despesas A receber  \\\n",
       "0                              Mariana   Direto  1.800,00                      \n",
       "1        Alex Palmer +55 63 99991 9458  Booking  1.084,02               0,00   \n",
       "2   ‪Weiman Pereira +55 66 98448-1056‬   Airbnb                       400,96   \n",
       "3      Paula Andrade +55 81 99716 3944  Booking    436,74               0,00   \n",
       "4           Cláudia +55 81 99974-5581‬   Airbnb    290,00             292,39   \n",
       "\n",
       "   Total Lq  Total BT Diária BT Diária Lq Com. Diária BT PAX Diária Lq PAX  \\\n",
       "0  1.800,00  1.800,00    450,00    450,00   0%         90,00         90,00   \n",
       "1  1.084,02  1.246,00    249,20    216,80  13%         49,84         43,36   \n",
       "2    400,96    490,26    245,13    200,48  18%        122,56        100,24   \n",
       "3    436,74    502,00    251,00    218,37  13%         50,20         43,67   \n",
       "4    582,39    712,09    356,05    291,20  18%         89,01         72,80   \n",
       "\n",
       "      Status Data Reserva  \n",
       "0  Concluído               \n",
       "1  Concluído               \n",
       "2  Concluído               \n",
       "3  Concluído               \n",
       "4  Concluído               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando salvamento do 'df_tratado' (1575 linhas)...\n",
      "\n",
      "--- Iniciando Upload para Google Sheet ---\n",
      "  Planilha Key: 1FqgTQAGebxvHUdVXI471HpAaXeXyCFdFWur7Pck0hLY\n",
      "  Aba         : Reservas Consolidadas\n",
      "Autenticando com conta de serviço...\n",
      "Autenticação OK.\n",
      "Abrindo planilha...\n",
      "Planilha aberta.\n",
      "Aba 'Reservas Consolidadas' encontrada.\n",
      "Limpando conteúdo existente da aba 'Reservas Consolidadas'...\n",
      "Aba limpa.\n",
      "Preparando dados para upload...\n",
      "Dados preparados: 1576 linhas, 20 colunas.\n",
      "Enviando dados para a aba 'Reservas Consolidadas' (iniciando em A1)...\n",
      "Dados enviados com sucesso!\n",
      "Ajustando o tamanho das colunas...\n",
      "Tamanho das colunas ajustado com sucesso.\n",
      "Adicionando filtro (Status=Em Branco) e ordenando por 'Início'...\n",
      "Autofiltro (Status=Branco) e ordenação por 'Início' aplicados com sucesso.\n",
      "\n",
      "Upload do DataFrame consolidado concluído com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# --- Configuração ---\n",
    "# Chave da sua planilha (extraída da URL)\n",
    "SHEET_KEY = '1FqgTQAGebxvHUdVXI471HpAaXeXyCFdFWur7Pck0hLY'\n",
    "# Arquivo de credenciais JSON da sua conta de serviço\n",
    "CREDS_FILE = 'credentials2.json' \n",
    "# O nome exato da aba onde os dados consolidados serão salvos\n",
    "WORKSHEET_NAME = 'Reservas Consolidadas'\n",
    "\n",
    "# A lista de abas que você quer ler\n",
    "abas_para_ler = [\n",
    "    'SM-C108',\n",
    "    'SM-D014',\n",
    "    'CBL004',\n",
    "    'AP-101',\n",
    "    'AP-201'\n",
    "]\n",
    "\n",
    "# --- Execução ---\n",
    "# Chama a função para ler todas as abas\n",
    "dfs_lidos = ler_abas_planilha(SHEET_KEY, abas_para_ler, CREDS_FILE)\n",
    "df_consolidado_final = unir_dataframes_lidos(dfs_lidos)\n",
    "# Chama a nova função de tratamento\n",
    "df_tratado = tratar_dataframe_consolidado(df_consolidado_final)\n",
    "display(df_tratado.head())\n",
    "\n",
    "# --- Verificação ---\n",
    "# Verifica se o DataFrame 'df_consolidado_final' (da sua célula anterior) existe\n",
    "if isinstance(df_consolidado_final, pd.DataFrame):\n",
    "    \n",
    "    if not df_tratado.empty:\n",
    "        print(f\"Iniciando salvamento do 'df_tratado' ({len(df_tratado)} linhas)...\")\n",
    "        \n",
    "        # --- Chamada da Função ---\n",
    "        sucesso_upload = salvar_df_no_gsheet(\n",
    "            df=df_tratado,\n",
    "            sheet_key=SHEET_KEY,\n",
    "            worksheet_name=WORKSHEET_NAME,\n",
    "            credentials_path=CREDS_FILE,\n",
    "            clear_sheet=True  # Garante que a aba será limpa antes de salvar\n",
    "        )\n",
    "\n",
    "        if sucesso_upload:\n",
    "            print(\"\\nUpload do DataFrame consolidado concluído com sucesso!\")\n",
    "        else:\n",
    "            print(\"\\nFalha no upload do DataFrame consolidado. Verifique os logs de erro.\")\n",
    "    else:\n",
    "        print(\"AVISO: 'df_consolidado_final' está vazio. Nada para salvar.\")\n",
    "\n",
    "else:\n",
    "    print(\"ERRO: A variável 'df_consolidado_final' não foi encontrada ou não é um DataFrame.\")\n",
    "    print(\"Por favor, execute a célula que define 'df_consolidado_final' (função 'unir_dataframes_lidos') primeiro.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
