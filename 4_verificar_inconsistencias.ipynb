{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4e0056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Necessário para verificar se os arquivos existem\n",
    "import pandas as pd\n",
    "from icalendar import Calendar\n",
    "from datetime import datetime, date, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44415a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ical_to_dataframe(file_path, prefix):\n",
    "    \"\"\"\n",
    "    Convert iCal file to DataFrame with specified column prefix\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to iCal file\n",
    "        prefix (str): Prefix for column names (e.g., 'OTA' or 'Google')\n",
    "    \"\"\"\n",
    "    events = []\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            cal = Calendar.from_ical(f.read())\n",
    "            \n",
    "        for event in cal.walk('VEVENT'):\n",
    "            start = event.get('dtstart').dt\n",
    "            end = event.get('dtend').dt\n",
    "            summary = str(event.get('summary'))\n",
    "            \n",
    "            # Convert to datetime if date\n",
    "            if isinstance(start, date) and not isinstance(start, datetime):\n",
    "                start = datetime.combine(start, time(hour=16))\n",
    "            if isinstance(end, date) and not isinstance(end, datetime):\n",
    "                end = datetime.combine(end, time(hour=11))\n",
    "                \n",
    "            events.append({\n",
    "                f'Origem': prefix,\n",
    "                f'Inicio': start,\n",
    "                f'Fim': end,\n",
    "                f'Summary': summary\n",
    "            })\n",
    "            \n",
    "        return pd.DataFrame(events)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {file_path}: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a2abd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def filtrar_reservas_passadas(df_original, data_corte):\n",
    "    \"\"\"\n",
    "    Filtra um DataFrame, removendo todas as linhas onde a data\n",
    "    na coluna 'Fim' é anterior (menor que) à data_corte fornecida.\n",
    "\n",
    "    Args:\n",
    "        df_original (pd.DataFrame): O DataFrame para filtrar (deve ter a coluna 'Fim').\n",
    "        data_corte (str or datetime): A data de referência (cutoff).\n",
    "                                      Linhas com 'Fim' < data_corte serão removidas.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Um novo DataFrame contendo apenas as linhas onde\n",
    "                      'Fim' >= data_corte, ou None se ocorrer um erro.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Validações Iniciais\n",
    "    if 'Fim' not in df_original.columns:\n",
    "        print(\"ERRO: O DataFrame não contém a coluna 'Fim'.\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"Iniciando filtro. (Tamanho original: {len(df_original)} linhas)\")\n",
    "    \n",
    "    # 2. Faz uma cópia para segurança (evita SettingWithCopyWarning)\n",
    "    df_filtrado = df_original.copy()\n",
    "\n",
    "    # 3. Converte a data_corte para um objeto datetime (Timestamp)\n",
    "    try:\n",
    "        # pd.to_datetime é robusto e lida com strings ou objetos datetime\n",
    "        data_corte_dt = pd.to_datetime(data_corte, errors='raise')\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO: A 'data_corte' fornecida ('{data_corte}') é inválida: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # 4. Garante que a coluna 'Fim' no DataFrame seja datetime\n",
    "    # errors='coerce' transforma datas inválidas (ex: 'Em Andamento') em NaT\n",
    "    df_filtrado['Fim'] = pd.to_datetime(df_filtrado['Fim'], errors='coerce')\n",
    "\n",
    "    # 5. Remove linhas com datas 'Fim' inválidas (que viraram NaT)\n",
    "    linhas_antes = len(df_filtrado)\n",
    "    df_filtrado.dropna(subset=['Fim'], inplace=True)\n",
    "    linhas_removidas_nat = linhas_antes - len(df_filtrado)\n",
    "    if linhas_removidas_nat > 0:\n",
    "        print(f\"  Aviso: Removidas {linhas_removidas_nat} linhas com data 'Fim' inválida ou vazia.\")\n",
    "\n",
    "    # 6. Aplica o filtro\n",
    "    # A condição para MANTER as linhas é 'Fim' >= 'data_corte'\n",
    "    linhas_antes_filtro = len(df_filtrado)\n",
    "    \n",
    "    condicao_manter = df_filtrado['Fim'] >= data_corte_dt\n",
    "    \n",
    "    df_resultado = df_filtrado[condicao_manter]\n",
    "    \n",
    "    linhas_removidas_passadas = linhas_antes_filtro - len(df_resultado)\n",
    "    print(f\"  Removidas {linhas_removidas_passadas} linhas com 'Fim' anterior a {data_corte_dt.strftime('%d/%m/%Y %H:%M')}.\")\n",
    "    print(f\"Filtro concluído. (Tamanho final: {len(df_resultado)} linhas)\")\n",
    "\n",
    "    return df_resultado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6654aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def filtrar_reservas_apos_1_ano(df_original, coluna_data='Inicio'):\n",
    "    \"\"\"\n",
    "    Filtra um DataFrame para remover reservas que começam\n",
    "    daqui a mais de um ano.\n",
    "\n",
    "    Args:\n",
    "        df_original (pd.DataFrame): DataFrame com as reservas.\n",
    "        coluna_data (str, optional): Nome da coluna de data (ex: 'Inicio') \n",
    "                                     para usar como base do filtro. \n",
    "                                     Default é 'Inicio'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame filtrado (apenas com linhas até 1 ano no futuro),\n",
    "                      ou None se a coluna de data não existir.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Verificar se a coluna de data existe\n",
    "    if coluna_data not in df_original.columns:\n",
    "        print(f\"ERRO: A coluna '{coluna_data}' não foi encontrada no DataFrame.\")\n",
    "        return None # Retorna None em caso de erro\n",
    "\n",
    "    df = df_original.copy()\n",
    "    linhas_originais = len(df)\n",
    "    print(f\"Iniciando filtro de 1 ano (linhas originais: {linhas_originais})...\")\n",
    "\n",
    "    # 2. Definir as datas de corte\n",
    "    # Usamos .normalize() para pegar a meia-noite de hoje (início do dia)\n",
    "    hoje = pd.to_datetime('today').normalize() \n",
    "    # Define a data limite (exatamente 1 ano a partir de hoje)\n",
    "    data_limite = hoje + pd.DateOffset(years=1)\n",
    "\n",
    "    print(f\"  Data de hoje (base): {hoje.strftime('%d/%m/%Y')}\")\n",
    "    print(f\"  Data limite (corte): {data_limite.strftime('%d/%m/%Y')}\")\n",
    "\n",
    "    # 3. Garantir que a coluna de data é datetime\n",
    "    # errors='coerce' transforma datas inválidas em NaT (Not a Time)\n",
    "    # (Se já for datetime, não faz mal)\n",
    "    df[coluna_data] = pd.to_datetime(df[coluna_data], errors='coerce')\n",
    "\n",
    "    # 4. Remover linhas com datas inválidas (NaT)\n",
    "    linhas_antes_nat = len(df)\n",
    "    df.dropna(subset=[coluna_data], inplace=True)\n",
    "    linhas_removidas_nat = linhas_antes_nat - len(df)\n",
    "    if linhas_removidas_nat > 0:\n",
    "        print(f\"  Aviso: Removidas {linhas_removidas_nat} linhas com data '{coluna_data}' inválida ou vazia.\")\n",
    "\n",
    "    # 5. Aplicar o filtro\n",
    "    # Queremos MANTER linhas onde a data é MENOR OU IGUAL à data limite\n",
    "    condicao_manter = df[coluna_data] <= data_limite\n",
    "    \n",
    "    df_resultado = df[condicao_manter]\n",
    "\n",
    "    linhas_removidas_futuro = len(df) - len(df_resultado)\n",
    "    print(f\"  Removidas {linhas_removidas_futuro} linhas com '{coluna_data}' posterior a {data_limite.strftime('%d/%m/%Y')}.\")\n",
    "    print(f\"Filtro concluído. (Tamanho final: {len(df_resultado)} linhas)\")\n",
    "\n",
    "    return df_resultado\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2fe56b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def remover_duplicatas_por_data(df_original):\n",
    "    \"\"\"\n",
    "    Remove TODAS as linhas de um DataFrame que compartilham\n",
    "    os mesmos valores nas colunas 'Inicio' e 'Fim'.\n",
    "\n",
    "    Se duas (ou mais) linhas têm o mesmo 'Inicio' e 'Fim',\n",
    "    todas essas linhas são excluídas. Apenas linhas com\n",
    "    combinações únicas de 'Inicio'/'Fim' são mantidas.\n",
    "\n",
    "    Args:\n",
    "        df_original (pd.DataFrame): DataFrame com colunas \n",
    "                                    'Origem', 'Inicio', 'Fim', 'Summary'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Um novo DataFrame contendo apenas as linhas\n",
    "                      com pares 'Inicio'/'Fim' únicos.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Colunas chave para verificar duplicatas\n",
    "    #colunas_chave = ['Inicio', 'Fim']\n",
    "    colunas_chave = ['Fim']\n",
    "    \n",
    "    # 1. Verifica se as colunas necessárias existem\n",
    "    if not all(col in df_original.columns for col in colunas_chave):\n",
    "        print(f\"ERRO: O DataFrame não contém as colunas necessárias: {colunas_chave}\")\n",
    "        return df_original # Retorna original se não puder processar\n",
    "\n",
    "    df = df_original.copy()\n",
    "    linhas_originais = len(df)\n",
    "    \n",
    "    print(f\"Iniciando verificação de duplicatas (linhas originais: {linhas_originais})...\")\n",
    "\n",
    "    # 2. Garante que as colunas de data sejam datetime para comparação correta\n",
    "    #    (Converte strings para datetime, se já forem datetime, não faz mal)\n",
    "    #    errors='coerce' transforma datas inválidas em NaT (Not a Time)\n",
    "    try:\n",
    "        df['Inicio'] = pd.to_datetime(df['Inicio'], errors='coerce')\n",
    "        df['Fim'] = pd.to_datetime(df['Fim'], errors='coerce')\n",
    "    except Exception as e:\n",
    "        print(f\"  Aviso: Falha ao converter colunas de data (podem já ser datetime). Erro: {e}\")\n",
    "        # Continua mesmo assim, pois duplicated() pode funcionar\n",
    "\n",
    "    # 3. Identifica TODAS as linhas que fazem parte de um grupo duplicado\n",
    "    #    keep=False marca TODAS as ocorrências de duplicatas como True.\n",
    "    #    Linhas únicas (incluindo NaTs únicos) são marcadas como False.\n",
    "    duplicados_mask = df.duplicated(subset=colunas_chave, keep=False)\n",
    "\n",
    "    # 4. Filtra o DataFrame, mantendo apenas as linhas que NÃO (~)\n",
    "    #    são parte de um grupo duplicado (ou seja, onde a máscara é False).\n",
    "    df_resultado = df[~duplicados_mask]\n",
    "    \n",
    "    linhas_removidas = linhas_originais - len(df_resultado)\n",
    "    print(f\"Processamento concluído. {linhas_removidas} linhas duplicadas foram removidas.\")\n",
    "    \n",
    "    return df_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54dee877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def encontrar_data_fim_mais_antiga_ota(df_reservas):\n",
    "    \"\"\"\n",
    "    Encontra a data mais antiga (mínima) na coluna 'Fim'\n",
    "    para todas as reservas cuja 'Origem' é 'OTA'.\n",
    "\n",
    "    Args:\n",
    "        df_reservas (pd.DataFrame): Um DataFrame que deve conter\n",
    "                                   as colunas 'Origem' e 'Fim'.\n",
    "\n",
    "    Returns:\n",
    "        pd.Timestamp or pd.NaT: A data mais antiga (mínima) encontrada.\n",
    "                                Retorna pd.NaT (Not a Time) se nenhuma\n",
    "                                reserva 'OTA' for encontrada ou se as\n",
    "                                datas forem inválidas.\n",
    "    \"\"\"\n",
    "    print(\"Iniciando busca pela data de 'Fim' mais antiga da 'OTA'...\")\n",
    "    \n",
    "    # --- 1. Verificação de Colunas ---\n",
    "    colunas_necessarias = ['Origem', 'Fim']\n",
    "    if not all(col in df_reservas.columns for col in colunas_necessarias):\n",
    "        print(f\"ERRO: O DataFrame não contém as colunas necessárias ({colunas_necessarias}).\")\n",
    "        return pd.NaT\n",
    "\n",
    "    try:\n",
    "        # --- 2. Filtrar por 'OTA' ---\n",
    "        # Seleciona apenas as linhas onde 'Origem' é 'OTA'\n",
    "        df_ota = df_reservas[df_reservas['Origem'] == 'OTA']\n",
    "\n",
    "        # --- 3. Verificar se algo foi encontrado ---\n",
    "        if df_ota.empty:\n",
    "            print(\"Aviso: Nenhuma reserva com 'Origem' = 'OTA' foi encontrada.\")\n",
    "            return pd.NaT\n",
    "\n",
    "        # --- 4. Garantir que 'Fim' é datetime ---\n",
    "        # Converte a coluna 'Fim' para datetime\n",
    "        # errors='coerce' transforma datas inválidas em NaT (Not a Time)\n",
    "        datas_fim_ota = pd.to_datetime(df_ota['Fim'], errors='coerce')\n",
    "\n",
    "        # --- 5. Encontrar a data mais antiga (mínima) ---\n",
    "        data_mais_antiga = datas_fim_ota.min()\n",
    "\n",
    "        if pd.isna(data_mais_antiga):\n",
    "            print(\"Aviso: Reservas 'OTA' encontradas, mas nenhuma data de 'Fim' válida.\")\n",
    "            return pd.NaT\n",
    "            \n",
    "        print(f\"Data mais antiga encontrada: {data_mais_antiga}\")\n",
    "        return data_mais_antiga\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO inesperado durante o processamento: {e}\")\n",
    "        return pd.NaT\n",
    "\n",
    "# --- Exemplo de Uso ---\n",
    "\n",
    "# # 1. Criar um DataFrame de exemplo\n",
    "# data = {\n",
    "#     'Origem': ['OTA', 'Google', 'Direto', 'OTA', 'OTA'],\n",
    "#     'Inicio': [\n",
    "#         '2025-11-01', '2025-10-25', '2025-10-28', '2025-10-20', '2025-11-05'\n",
    "#     ],\n",
    "#     'Fim': [\n",
    "#         '2025-11-10', '2025-10-27', '2025-10-30', '2025-10-24', '2025-11-08'\n",
    "#     ],\n",
    "#     'Summary': ['Reserva A', 'Reserva B', 'Reserva C', 'Reserva D', 'Reserva E']\n",
    "# }\n",
    "# df_exemplo = pd.DataFrame(data)\n",
    "# \n",
    "# # Adicionar uma data inválida\n",
    "# df_exemplo.loc[len(df_exemplo)] = ['OTA', '2025-12-01', 'Data Inválida', 'Reserva F']\n",
    "\n",
    "# print(\"--- DataFrame de Exemplo ---\")\n",
    "# display(df_exemplo)\n",
    "\n",
    "# # 2. Chamar a função\n",
    "# data_antiga = encontrar_data_fim_mais_antiga_ota(df_exemplo)\n",
    "\n",
    "# if pd.notna(data_antiga):\n",
    "#     print(f\"\\nResultado Final: A data de 'Fim' mais antiga da 'OTA' é: {data_antiga.strftime('%d/%m/%Y')}\")\n",
    "# else:\n",
    "#     print(\"\\nResultado Final: Não foi possível determinar a data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa6747f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando verificação de inconsistências ---\n",
      "\n",
      "--- Verificando Apartamento: C108 ---\n",
      "Iniciando busca pela data de 'Fim' mais antiga da 'OTA'...\n",
      "Data mais antiga encontrada: 2025-12-19 11:00:00\n",
      "Iniciando filtro. (Tamanho original: 58 linhas)\n",
      "  Removidas 40 linhas com 'Fim' anterior a 19/12/2025 11:00.\n",
      "Filtro concluído. (Tamanho final: 18 linhas)\n",
      "Iniciando filtro de 1 ano (linhas originais: 18)...\n",
      "  Data de hoje (base): 13/12/2025\n",
      "  Data limite (corte): 13/12/2026\n",
      "  Removidas 0 linhas com 'Inicio' posterior a 13/12/2026.\n",
      "Filtro concluído. (Tamanho final: 18 linhas)\n",
      "Iniciando verificação de duplicatas (linhas originais: 18)...\n",
      "Processamento concluído. 18 linhas duplicadas foram removidas.\n",
      "=== Nenhuma inconsistência encontrada em C108 ===\n",
      "\n",
      "--- Verificando Apartamento: D014 ---\n",
      "Iniciando busca pela data de 'Fim' mais antiga da 'OTA'...\n",
      "Data mais antiga encontrada: 2025-12-18 11:00:00\n",
      "Iniciando filtro. (Tamanho original: 30 linhas)\n",
      "  Removidas 12 linhas com 'Fim' anterior a 18/12/2025 11:00.\n",
      "Filtro concluído. (Tamanho final: 18 linhas)\n",
      "Iniciando filtro de 1 ano (linhas originais: 18)...\n",
      "  Data de hoje (base): 13/12/2025\n",
      "  Data limite (corte): 13/12/2026\n",
      "  Removidas 0 linhas com 'Inicio' posterior a 13/12/2026.\n",
      "Filtro concluído. (Tamanho final: 18 linhas)\n",
      "Iniciando verificação de duplicatas (linhas originais: 18)...\n",
      "Processamento concluído. 18 linhas duplicadas foram removidas.\n",
      "=== Nenhuma inconsistência encontrada em D014 ===\n",
      "\n",
      "--- Verificando Apartamento: CBL004 ---\n",
      "Iniciando busca pela data de 'Fim' mais antiga da 'OTA'...\n",
      "Data mais antiga encontrada: 2025-12-15 11:00:00\n",
      "Iniciando filtro. (Tamanho original: 393 linhas)\n",
      "  Removidas 363 linhas com 'Fim' anterior a 15/12/2025 11:00.\n",
      "Filtro concluído. (Tamanho final: 30 linhas)\n",
      "Iniciando filtro de 1 ano (linhas originais: 30)...\n",
      "  Data de hoje (base): 13/12/2025\n",
      "  Data limite (corte): 13/12/2026\n",
      "  Removidas 0 linhas com 'Inicio' posterior a 13/12/2026.\n",
      "Filtro concluído. (Tamanho final: 30 linhas)\n",
      "Iniciando verificação de duplicatas (linhas originais: 30)...\n",
      "Processamento concluído. 30 linhas duplicadas foram removidas.\n",
      "=== Nenhuma inconsistência encontrada em CBL004 ===\n",
      "\n",
      "--- Verificando Apartamento: AP101 ---\n",
      "Iniciando busca pela data de 'Fim' mais antiga da 'OTA'...\n",
      "Data mais antiga encontrada: 2025-12-15 11:00:00\n",
      "Iniciando filtro. (Tamanho original: 595 linhas)\n",
      "  Removidas 554 linhas com 'Fim' anterior a 15/12/2025 11:00.\n",
      "Filtro concluído. (Tamanho final: 41 linhas)\n",
      "Iniciando filtro de 1 ano (linhas originais: 41)...\n",
      "  Data de hoje (base): 13/12/2025\n",
      "  Data limite (corte): 13/12/2026\n",
      "  Removidas 1 linhas com 'Inicio' posterior a 13/12/2026.\n",
      "Filtro concluído. (Tamanho final: 40 linhas)\n",
      "Iniciando verificação de duplicatas (linhas originais: 40)...\n",
      "Processamento concluído. 40 linhas duplicadas foram removidas.\n",
      "=== Nenhuma inconsistência encontrada em AP101 ===\n",
      "\n",
      "--- Verificando Apartamento: AP201 ---\n",
      "Iniciando busca pela data de 'Fim' mais antiga da 'OTA'...\n",
      "Data mais antiga encontrada: 2025-12-15 11:00:00\n",
      "Iniciando filtro. (Tamanho original: 602 linhas)\n",
      "  Removidas 550 linhas com 'Fim' anterior a 15/12/2025 11:00.\n",
      "Filtro concluído. (Tamanho final: 52 linhas)\n",
      "Iniciando filtro de 1 ano (linhas originais: 52)...\n",
      "  Data de hoje (base): 13/12/2025\n",
      "  Data limite (corte): 13/12/2026\n",
      "  Removidas 0 linhas com 'Inicio' posterior a 13/12/2026.\n",
      "Filtro concluído. (Tamanho final: 52 linhas)\n",
      "Iniciando verificação de duplicatas (linhas originais: 52)...\n",
      "Processamento concluído. 52 linhas duplicadas foram removidas.\n",
      "=== Nenhuma inconsistência encontrada em AP201 ===\n",
      "\n",
      "--- Verificando Apartamento: F216 ---\n",
      "Iniciando busca pela data de 'Fim' mais antiga da 'OTA'...\n",
      "Data mais antiga encontrada: 2025-12-15 11:00:00\n",
      "Iniciando filtro. (Tamanho original: 7 linhas)\n",
      "  Removidas 0 linhas com 'Fim' anterior a 15/12/2025 11:00.\n",
      "Filtro concluído. (Tamanho final: 7 linhas)\n",
      "Iniciando filtro de 1 ano (linhas originais: 7)...\n",
      "  Data de hoje (base): 13/12/2025\n",
      "  Data limite (corte): 13/12/2026\n",
      "  Removidas 0 linhas com 'Inicio' posterior a 13/12/2026.\n",
      "Filtro concluído. (Tamanho final: 7 linhas)\n",
      "Iniciando verificação de duplicatas (linhas originais: 7)...\n",
      "Processamento concluído. 0 linhas duplicadas foram removidas.\n",
      "=== Encontradas 7 inconsistências em F216 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origem</th>\n",
       "      <th>Inicio</th>\n",
       "      <th>Fim</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OTA</td>\n",
       "      <td>2025-12-11 16:00:00</td>\n",
       "      <td>2025-12-15 11:00:00</td>\n",
       "      <td>Airbnb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OTA</td>\n",
       "      <td>2025-12-20 16:00:00</td>\n",
       "      <td>2025-12-23 11:00:00</td>\n",
       "      <td>Airbnb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OTA</td>\n",
       "      <td>2025-12-23 16:00:00</td>\n",
       "      <td>2025-12-30 11:00:00</td>\n",
       "      <td>Airbnb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OTA</td>\n",
       "      <td>2026-01-05 16:00:00</td>\n",
       "      <td>2026-01-09 11:00:00</td>\n",
       "      <td>Airbnb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OTA</td>\n",
       "      <td>2025-12-15 16:00:00</td>\n",
       "      <td>2025-12-20 11:00:00</td>\n",
       "      <td>Direto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OTA</td>\n",
       "      <td>2026-01-09 16:00:00</td>\n",
       "      <td>2026-01-11 11:00:00</td>\n",
       "      <td>Direto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OTA</td>\n",
       "      <td>2026-05-01 16:00:00</td>\n",
       "      <td>2026-05-04 11:00:00</td>\n",
       "      <td>Direto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Origem              Inicio                 Fim Summary\n",
       "0    OTA 2025-12-11 16:00:00 2025-12-15 11:00:00  Airbnb\n",
       "1    OTA 2025-12-20 16:00:00 2025-12-23 11:00:00  Airbnb\n",
       "2    OTA 2025-12-23 16:00:00 2025-12-30 11:00:00  Airbnb\n",
       "3    OTA 2026-01-05 16:00:00 2026-01-09 11:00:00  Airbnb\n",
       "4    OTA 2025-12-15 16:00:00 2025-12-20 11:00:00  Direto\n",
       "5    OTA 2026-01-09 16:00:00 2026-01-11 11:00:00  Direto\n",
       "6    OTA 2026-05-01 16:00:00 2026-05-04 11:00:00  Direto"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Salvando em f216_inconsistencias.csv ===\n",
      "\n",
      "--- Verificação de todos os apartamentos concluída! ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Iniciando verificação de inconsistências ---\")\n",
    "\n",
    "# 1. Defina a lista de apartamentos para iterar\n",
    "apartment_list = [\n",
    "    'c108', \n",
    "    'd014', \n",
    "    'cbl004',\n",
    "    'ap101',\n",
    "    'ap201',\n",
    "    'f216',\n",
    "]\n",
    "\n",
    "# 2. Itere sobre a lista\n",
    "for apt in apartment_list:\n",
    "    print(f\"\\n--- Verificando Apartamento: {apt.upper()} ---\")\n",
    "\n",
    "    # 3. Defina os caminhos dos arquivos\n",
    "    file_ota = f'calendars/{apt}_merged_booking_airbnb.ics'\n",
    "    file_google = f'calendars/{apt}_google.ics'\n",
    "\n",
    "    # 4. Verifique se os arquivos necessários existem\n",
    "    if not os.path.exists(file_ota) or not os.path.exists(file_google):\n",
    "        print(f\"Aviso: Pulando {apt.upper()}. Um ou mais arquivos .ics não foram encontrados.\")\n",
    "        if not os.path.exists(file_ota):\n",
    "            print(f\"  -> {file_ota} (Não encontrado)\")\n",
    "        if not os.path.exists(file_google):\n",
    "            print(f\"  -> {file_google} (Não encontrado)\")\n",
    "        continue # Pula para o próximo apartamento no loop\n",
    "\n",
    "    # 5. Execute a comparação (os arquivos existem)\n",
    "    try:\n",
    "        # Convert both files to DataFrames\n",
    "        df_ota = ical_to_dataframe(file_ota, 'OTA')\n",
    "        df_google = ical_to_dataframe(file_google, 'Google')\n",
    "        df_final = pd.concat([df_ota, df_google], ignore_index=True)\n",
    "        \n",
    "        data_corte = encontrar_data_fim_mais_antiga_ota(df_final)\n",
    "\n",
    "        df_final = filtrar_reservas_passadas(df_final, data_corte)\n",
    "        \n",
    "        # 2. Chamar a função (usando a coluna padrão 'Inicio')\n",
    "        df_final = filtrar_reservas_apos_1_ano(df_final)\n",
    "        \n",
    "        df_final = remover_duplicatas_por_data(df_final)\n",
    "        \n",
    "        \n",
    "        if df_final is None:\n",
    "             print(f\"Função remover_duplicatas_por_data retornou 'None' para {apt.upper()}. Pulando.\")\n",
    "             continue\n",
    "\n",
    "        inconsistencies = df_final\n",
    "\n",
    "        # 6. Exiba os resultados\n",
    "        if inconsistencies is not None and not inconsistencies.empty:\n",
    "            print(f\"=== Encontradas {len(inconsistencies)} inconsistências em {apt.upper()} ===\")\n",
    "            display(inconsistencies)\n",
    "            print(f\"=== Salvando em {apt}_inconsistencias.csv ===\")\n",
    "            inconsistencies.to_csv(f'calendars/{apt}_inconsistencias.csv', index=False, quoting=1)\n",
    "        else:\n",
    "            print(f\"=== Nenhuma inconsistência encontrada em {apt.upper()} ===\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ERRO: Ocorreu uma exceção inesperada ao processar {apt.upper()}: {e}\")\n",
    "\n",
    "print(\"\\n--- Verificação de todos os apartamentos concluída! ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
